{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Snowball Samples From Facebook 'Seed' Page(s) \n",
    "\n",
    "If you are interested in analyzing social media, one of the main challenges is figuring out where to start!\n",
    "\n",
    "Perhaps you are interested in identifying which sources of information are influential within partisan Facebook pages or groups? Uncovering behavioral patterns that may indicate coordination by Facebook pages to advance partisan narratives? Identifying information echo-chambers that are susceptible to partisan information (and disinformation)? or extracting topics that are being pushed -- or are gaining traction -- within partisan ecosystems?\n",
    "\n",
    "These are questions that require some manner of identifying partisan ecosystems - ideologically like-minded Facebook pages and groups - for research and analysis purposes. Unfortunately, there is no census of Facebook pages and groups from which you could draw a random sample and draw generalizable conclusions. In the absence of comprehensive sampling frame, you could use a form of 'snowball sampling' -- a non-random approach that relies on 'referrals' from identified sources -- to find like-minded pages and groups.\n",
    "\n",
    "To draw a snowball sample of Facebook pages and groups that may form a partisan ecosystem, we need to first identify 'seed' pages that have large numbers of followers and are understood to be representative of a partisan agenda, e.g. if we wanted to study the 'Pro-Trump' ecosystem, a 'seed' would be Donald Trump's Facebook page. Once we have identifed a seed page(s), we then want to find pages and groups that have recently shared content from that page and, for the most part, are like-minded supporters and / or share similar political views.*\n",
    "\n",
    "**This is not universally true -- sometimes non-supporters share content from seed pages for the purposes of condemning it, or media outlets share content because it is newsworthy. These non-supporters pages and groups need to be weeded out through Social Network Analysis and Community Detection techniques which will be demonstrated in the next post.*\n",
    "\n",
    "In this example, we are interested in analyzing social media behavior among pro-Georgia Republican groups engaged in political discourse ahead of the January 5, 2021 runoff election. We will draw a snowball sample to identify Pro-Republican Facebook pages and groups, with a specific goal of identifying pro-Georgia Republican Facebook groups for deeper analysis. We will start with three 'seed' pages: The Georgia Republican Party's Facebook page (130K+ followers), David Perdue's Facebook page (80K+) and Kelly Loeffler's Facebook page (35K+).  \n",
    "\n",
    "To draw a snowball sample of Facebook pages and groups, we will rely on the CrowdTangle API* to find the last 1,000 shares of post content from these seed pages. Once we have found pages and groups that have shared content from these seed pages, we will upload the snowball pages and groups to lists in CrowdTangle (\"Republican Pages\" and \"Republican Groups\").\n",
    "\n",
    "**CrowdTangle is an intermediary for accessing data from Facebook. You will need to create a CrowdTangle dashboard for this analysis and create lists to which to upload batches of pages and groups that you will analyze. To use the CrowdTangle API, you can obtain the API token for the dashboard via \"API Access\" in the settings menu. If you don't have API access, ask the CrowdTangle adminstrator in your organization.*\n",
    "\n",
    "Once these snowball pages and groups are in CrowdTangle, we grab posts from sample groups to analyze behavior. Specifically, we'll grab the last 10,000 posts from a snowball sample of groups (given API rate limits imposed by CrowdTangle, we'll create a database in which store posts data obtained from sample groups for efficiency and accessibility in future posts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import packages needed for script, add API token from the CrowdTangle dashboard you created, and add a database connection to store posts data we collect from sample groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import collections\n",
    "from datetime import datetime, timedelta \n",
    "import time\n",
    "import pyodbc \n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#crowdtangle token:\n",
    "token = 'your_dashboard_token'\n",
    "\n",
    "#database connection:\n",
    "connection_string = 'your_database_connection_string'\n",
    "engine = create_engine(connection_string, encoding='utf8')\n",
    "db = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will create a 'get_links' function (CrowdTangle Links API wrapper) to use to get last 1,000 post shares from a 'seed' page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(token, link, platforms='facebook', count=1000):\n",
    "    api_url_base = \"https://api.crowdtangle.com/links?token=\"\n",
    "    link_pre = '&link='\n",
    "    count_pre = '&count='\n",
    "    plat_pre = '&platforms='\n",
    "    api_url = format(f'{api_url_base}{token}{link_pre}{link}{plat_pre}{platforms}{count_pre}{count}')\n",
    "    response = requests.get(api_url)   \n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.content.decode('utf-8'))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we pass the links to the 'seed' pages from which we want to grab last 1,000 post shares to the 'get_links' function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gagop_snowball = get_links(token, link='facebook.com/GAGOP') #Georgia Republican Party \n",
    "loeffler_snowball = get_links(token, link='facebook.com/KellyLoefflerGA') #Kelly Loeffler \n",
    "perdue_snowball = get_links(token, link='facebook.com/perduesenate') #David Perdue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a quick peek at the names of some of the pages and groups that were drawn in our snowball sample because they have shared content from the Georgia Republican Facebook page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accountType</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>David Perdue</td>\n",
       "      <td>facebook_page</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Law Enforcement Officers and patriots for Pres...</td>\n",
       "      <td>facebook_page</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>HOLD THE LINE January 5th</td>\n",
       "      <td>facebook_group</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Gwinnett County Republican Party</td>\n",
       "      <td>facebook_page</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Harris County, Georgia, Republican Party</td>\n",
       "      <td>facebook_page</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Georgia Republican Party</td>\n",
       "      <td>facebook_page</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Floyd County Republican Party</td>\n",
       "      <td>facebook_page</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Pickens County Georgia Republican Party</td>\n",
       "      <td>facebook_page</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Latinos For Trump -Georgia</td>\n",
       "      <td>facebook_page</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Dear President Trump</td>\n",
       "      <td>facebook_group</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name     accountType  shares\n",
       "51                                        David Perdue   facebook_page     424\n",
       "109  Law Enforcement Officers and patriots for Pres...   facebook_page      41\n",
       "89                           HOLD THE LINE January 5th  facebook_group      37\n",
       "87                    Gwinnett County Republican Party   facebook_page      25\n",
       "93            Harris County, Georgia, Republican Party   facebook_page      18\n",
       "78                            Georgia Republican Party   facebook_page      17\n",
       "64                       Floyd County Republican Party   facebook_page      14\n",
       "139            Pickens County Georgia Republican Party   facebook_page      13\n",
       "108                         Latinos For Trump -Georgia   facebook_page      11\n",
       "52                                Dear President Trump  facebook_group      10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gagop_snowball_sample = pd.DataFrame.from_dict(gagop_snowball['result']['posts'])\n",
    "gagop_snowball_sample = pd.concat([gagop_snowball_sample.drop(['account'], axis=1), gagop_snowball_sample['account'].apply(pd.Series)], axis=1)\n",
    "gagop_snowball_sample.groupby(['name', 'accountType']).size().to_frame().reset_index().rename(columns={0: 'shares'}).sort_values(by='shares', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a pretty good snowball sample for studying Georgia Republican pages and groups!\n",
    "\n",
    "Next we create a 'prep_batch' function to prepare the pages and groups that have shared posts from these pages for batch upload to the CrowdTangle dashboard we created (be sure that you have created empty lists to store these pages and groups in your CrowdTangle dashboard!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_batch(data, atype='pages', minsize=0, listname='null'):\n",
    "    df = pd.DataFrame.from_dict(data['result']['posts'])\n",
    "    df = pd.concat([df.drop(['account'], axis=1), df['account'].apply(pd.Series)], axis=1)\n",
    "    df = df.groupby(['name', 'url', 'accountType']).size().to_frame().reset_index().sort_values(by=0, ascending=False)\n",
    "    if atype == 'pages':\n",
    "        df1 = df.loc[((df['accountType'] == 'facebook_page') & (df[0] > minsize))]\n",
    "    else: #need to fix the else to set to 'groups' as an option -- not a big deal right now\n",
    "        df1 = df.loc[((df['accountType'] == 'facebook_group') & (df[0] > minsize))]\n",
    "    df1['List'] = listname\n",
    "    df1 = df1.rename(columns={\"url\": \"Page or Account URL\"}).reset_index(drop=True)\n",
    "    return df1[['Page or Account URL', 'List']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run stored results of post shares through batch upload prep function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "gagop_snowball_pg_batch = prep_batch(gagop_snowball, atype='pages', minsize=1, listname='Republican Snowball Pages')\n",
    "gagop_snowball_gp_batch = prep_batch(gagop_snowball, atype='groups', minsize=1, listname='Republican Snowball Pages')\n",
    "loeffler_snowball_pg_batch = prep_batch(loeffler_snowball, atype='pages', minsize=1, listname='Republican Snowball Pages')\n",
    "loeffler_snowball_gp_batch = prep_batch(loeffler_snowball, atype='groups', minsize=1, listname='Republican Snowball Groups')\n",
    "perdue_snowball_pg_batch = prep_batch(perdue_snowball, atype='pages', minsize=1, listname='Republican Snowball Pages')\n",
    "perdue_snowball_gp_batch = prep_batch(perdue_snowball, atype='groups', minsize=1, listname='Republican Snowball Groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export CSV files for batch upload to CrowdTangle -- this will export 6 CSV files for batch upload. Don't worry about duplication - CrowdTangle will handle duplicates and will not include the same page or group twice in a list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gagop_snowball_pg_batch.to_csv(\"gagop_snowball_pages.csv\", index=False)\n",
    "gagop_snowball_gp_batch.to_csv(\"gagop_snowball_groups.csv\", index=False)\n",
    "loeffler_snowball_pg_batch.to_csv(\"loeffler_snowball_pages.csv\", index=False)\n",
    "loeffler_snowball_gp_batch.to_csv(\"loeffler_snowball_groups.csv\", index=False)\n",
    "perdue_snowball_pg_batch.to_csv(\"perdue_snowball_pages.csv\", index=False)\n",
    "perdue_snowball_gp_batch.to_csv(\"perdue_snowball_groups.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have uploaded these pages and groups via batch upload to CrowdTangle, we can grab posts from the snowball sample. For this example, we'll grab the last 10,000 posts from the Oromo Groups sample.\n",
    "\n",
    "We create a 'get_lists' function (CrowdTangle Lists API wrapper) to use to access all lists in the dashboard that have been created. Then we will grab the id of the list of sample groups from which you want to collect up to the last 10,000 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1490375, 'title': 'Republican Snowball Pages', 'type': 'LIST'},\n",
       " {'id': 1490376, 'title': 'Republican Snowball Groups', 'type': 'LIST'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_list_info():\n",
    "    ctapi_list = 'https://api.crowdtangle.com/lists?token='\n",
    "    api_url = format(f'{ctapi_list}{token}')\n",
    "    response = requests.get(api_url)\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.content.decode('utf-8'))\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "list_info = get_list_info()\n",
    "list_info['result']['lists']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list id for the Republican Snowball Groups sample we just created is '1490376'.\n",
    "\n",
    "We create a 'get_posts' function (CrowdTangle Posts API wrapper) to get up to last 10,000 posts from sample during date range provided.\n",
    "\n",
    "We'll set a custom date range even though we will only get the last 10,000 posts available (NB: it's unnecessary for this example, but the custom date range is included here for illustrative purposes to highlight how you can adjust the date range to a specific window of time to retrieve posts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = '1490376' #Republican Snowball Groups\n",
    "start = '2020-11-29' #Nov 29 2020\n",
    "end = '2020-12-28' #Dec 28 2020\n",
    "allposts = []\n",
    "def get_posts():\n",
    "    ctapi_posts = 'https://api.crowdtangle.com/posts?token='\n",
    "    start_date = '&startDate='\n",
    "    end_date = '&endDate=' \n",
    "    listids = '&listIds='\n",
    "    count = '&count='\n",
    "    n = '100'\n",
    "    offset = '&offset='\n",
    "    sortBy = '&sortBy='\n",
    "    sort = 'total_interactions'\n",
    "    api_url = format(f'{ctapi_posts}{token}{listids}{idx}{start_date}{start}{end_date}{end}{count}{n}{sortBy}{sort}{offset}')\n",
    "    for o in range(0,10000,100):\n",
    "        api_call = api_url + str(o)\n",
    "        response = requests.get(api_call).json()\n",
    "        time.sleep(10)\n",
    "        allposts.append(response)\n",
    "        print(api_call)\n",
    "        \n",
    "def posts_toframe(allposts):\n",
    "    temp = pd.DataFrame(allposts)\n",
    "    temp = pd.concat([temp.drop(['result'], axis=1), temp['result'].apply(pd.Series)], axis=1)\n",
    "    temp = temp.explode('posts')\n",
    "    temp = pd.concat([temp.drop(['posts'], axis=1), temp['posts'].apply(pd.Series)], axis=1)\n",
    "    temp = temp.rename(columns={\"subscriberCount\": \"initialSubscriberCount\", \"id\": \"initialId\", \"platformId\": \"initialPlatformId\", \"platform\": \"initialPlatform\"})\n",
    "#expand account data into individual columns\n",
    "    temp = pd.concat([temp.drop(['account'], axis=1), temp['account'].apply(pd.Series)], axis=1)\n",
    "#expand statistics data into invidivual columns\n",
    "    temp = pd.concat([temp.drop(['statistics'], axis=1), temp['statistics'].apply(pd.Series)], axis=1)\n",
    "    temp = pd.concat([temp.drop(['actual'], axis=1), temp['actual'].apply(pd.Series)], axis=1)\n",
    "    temp['date'] = pd.to_datetime(temp.date)\n",
    "    temp['updated'] = pd.to_datetime(temp.updated)\n",
    "    temp['id'] = temp['id'].astype(object)\n",
    "    temp = temp.drop(['status', 'pagination'], axis=1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the get_posts function to retrieve the last 10,000 posts. \n",
    "Note: to address API rate limits, the get_posts function takes 15+ minutes to run (now's a good time to brew another pot of coffee).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_posts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll convert the data we just obtained to a dataframe and have a quick peek at the number of groups for which we have post data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sarah Sanders Fox News Fans', 'Flip it Red California',\n",
       "       'HOLD THE LINE January 5th', 'We the People of Georgia Group',\n",
       "       'Keep Georgia Red', 'TRUMP ~ The Next Four Years',\n",
       "       'Nikki Haley for POTUS, 2024', 'Grassroots For Doug Collins',\n",
       "       'Trump Women Landslide 2020', 'THE TRUMPERS!!!',\n",
       "       'Georgia Democrats', 'The Silent Majority Group',\n",
       "       'WAYCROSS & BLACKSHEAR GA NEWS', 'OfficialLatinosForTrump',\n",
       "       'Friends Who Like Sean Hannity', 'Georgians for Kelly Loeffler',\n",
       "       'Hart County Republicans', 'Patriots For Trump',\n",
       "       'Citizens of Berrien County, Georgia',\n",
       "       'Georgia Republicans United',\n",
       "       'Republican National Hispanic Assembly - Official Group',\n",
       "       'Southest GA Conservatives',\n",
       "       'Nationwide Support for Donald J. Trump',\n",
       "       'Australians for Donald Trump', 'Keep Cobb Conservative',\n",
       "       'Concerned Citizens of Whitfield and Murray County',\n",
       "       'Georgia 14th District Conservative Patriots', 'TRUMP VICTORY USA',\n",
       "       'SOUTHEAST GA BULLETIN BOARD', 'Northwest GA Civil Defense League',\n",
       "       'Floyd Co./Rome, Ga. Respectful Discussions About Important Issues',\n",
       "       \"Cobb County Republican Women's Club\",\n",
       "       'PCRW Political discussions Group',\n",
       "       'Independence of Human Rights Defenders ICCPR',\n",
       "       'Forty-Five 2020 Group', '1 MILLION People to DEFEAT Barack Obama',\n",
       "       'Save the Supreme court', 'GA Women for Trump',\n",
       "       'Carroll County Georgia Republican Party',\n",
       "       'Georgia Republican Party 11th Congressional District',\n",
       "       'Largest group ever we need 10,000,000 members to make america great again!',\n",
       "       'Barrow County Republican Party Official FB group',\n",
       "       'Eye On 2020 Trumpers',\n",
       "       'Georgia’s 14th District Second Amendment Supporters For Marjorie Greene',\n",
       "       'Republicans for freedom',\n",
       "       'Nassau County Fl residents for the Constitution of the United States'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "republican_snowball_group_posts = posts_toframe(allposts)\n",
    "republican_snowball_group_posts['name'].nunique() #how many unique groups\n",
    "republican_snowball_group_posts['name'].unique() #unique group names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also take a peek at a sample of the messages in some of our sample groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>This is fantastic news about the election. I a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>https://www.thedailybeast.com/value-of-sen-kel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A takeaway from a local meeting tonight: URGEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>HAPPENING NOW!! Fulton County voting machines ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>If you are going to watch ANYTHING today, WATC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>“Target Date: January 6, 2021” by Joe Esposito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>If I were Brian Kemp, and thank God I ain't, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\"Incredible as it may seem, the future of our ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Does anyone know which legislators are backing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>I emailed all the Republican Senators around t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>IN THE MATTER OF: TEXAS PLAINTIFF v. PENNSYLVA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>New lawsuit filed in Georgia today which is jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Treated very poorly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>As usual, Democrats do not want their true bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wonder if Zuck's acolytes will let me expose t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Who thinks that Republicans should have voted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Did you know Gavin Newsom banned indoor servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>It must be getting to the State elected offici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Have a neighbor that jus received an absentee ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Love it!!! https://www.facebook.com/1307033636...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message\n",
       "15  This is fantastic news about the election. I a...\n",
       "86  https://www.thedailybeast.com/value-of-sen-kel...\n",
       "17  A takeaway from a local meeting tonight: URGEN...\n",
       "59  HAPPENING NOW!! Fulton County voting machines ...\n",
       "69  If you are going to watch ANYTHING today, WATC...\n",
       "61  “Target Date: January 6, 2021” by Joe Esposito...\n",
       "72  If I were Brian Kemp, and thank God I ain't, I...\n",
       "35  \"Incredible as it may seem, the future of our ...\n",
       "41  Does anyone know which legislators are backing...\n",
       "83  I emailed all the Republican Senators around t...\n",
       "69  IN THE MATTER OF: TEXAS PLAINTIFF v. PENNSYLVA...\n",
       "90  New lawsuit filed in Georgia today which is jo...\n",
       "54                                Treated very poorly\n",
       "66  As usual, Democrats do not want their true bel...\n",
       "96  Wonder if Zuck's acolytes will let me expose t...\n",
       "71  Who thinks that Republicans should have voted ...\n",
       "9   Did you know Gavin Newsom banned indoor servic...\n",
       "68  It must be getting to the State elected offici...\n",
       "79  Have a neighbor that jus received an absentee ...\n",
       "18  Love it!!! https://www.facebook.com/1307033636..."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "republican_snowball_group_posts[['message']][republican_snowball_group_posts['message'].notnull()].sample(n=20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we've pulled a sample with a decent amount of post content related to the Georgia runoffs as well as a mixture of other political content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll process the data we just collected and prepare it for storage in our database for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#republican_snowball_group_posts = republican_snowball_group_posts.drop([0], axis=1) #removes all columns with name '0'\n",
    "republican_snowball_group_posts = republican_snowball_group_posts.drop(['expandedLinks', 'media', 'expected'], axis=1) #removes columns which have list objects as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "republican_snowball_group_posts.to_sql(\"republican_groups_snowball_posts\", db, if_exists='replace', schema=None, index=False, chunksize=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now got posts from our snowball sample of Republican groups stored in our database for easy access and analysis. \n",
    "\n",
    "In the next notebook, we'll conduct a Social Network Analysis and use a Community Detection algorithm to identify sub-clusters of interest for even deeper analysis. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
